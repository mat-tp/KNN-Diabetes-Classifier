K NEAREST NEIGHBORS (KNN)
Description:

This project is designed to calculate the k nearest neighbors (KNN) used for making predictions on whether a given test dataset indicates a person is Diabetic or Not. The dataset used is from Kaggle (diabetes.csv).

In this project, I utilized the Math library (common.math3-3.6.1.jar) from Apache, which aids in matrix calculations and the transformation of arrays into matrices.
FOR USE:

    Download the Project:
        Ensure you have Java properly installed on your system.

    Set Up the Project:
        I recommend creating a new project in either Eclipse or IntelliJ.
        Copy all downloaded files into the folder of your new project. (I used Eclipse for this project setup.)

    Add External Libraries:
        Make sure to include the Math3.jar file as an external library and add it to your build path to enable matrix operations.

CONCLUSIONS:

In this project, I explored how to approach the KNN algorithm for classification tasks. However, I acknowledge that this may not be the most optimal solution for this classification problem, and further improvements could be made.
THE PROJECT LACKS MORE:

    The project lacks further optimizations and more sophisticated feature engineering.
    It could benefit from additional validation techniques, hyperparameter tuning, and possibly alternative algorithms for comparison.

MORE MODIFICATIONS TO CONSIDER:

    Refactoring the Code: The current code can be refactored to improve efficiency and readability.
    Choosing the Best Value of K: At a later stage, I plan to implement functionality that allows automatic selection of the best value of K based on accuracy.
    User Input for Testing Real-World Data: Adding a feature to allow users to input their desired test data for real-world predictions would make the model more interactive.
    Evaluation and Metrics: Additional evaluation metrics (e.g., precision, recall, F1-score) could be incorporated to assess the model's performance better.

But none the less, this project serves as a great starting point, and you can see the results derived from the test set of the data. As I said, this was a wonderful project to get to work on.
